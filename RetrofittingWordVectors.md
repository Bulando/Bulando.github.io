<h2>Retrofitting Word Vectors to Semantic Lexicons论文翻译</h2>


<h2>改进词向量到语义词典</h2>

Mannal Faruqui; Jesse Dodge; Sujay K.Jauhar; Chris Dyer; Eduard Hovy; Noah A.Smith;

<h3>摘要</h3>

从大型语料库中词汇的分布信息中学习向量空间词汇表示。尽管这样的统计数据在语义上提供了信息，但它们忽略了语义词典(如WordNet、FrameNet和意译数据库)中包含的有价值的信息。本文提出了一种利用语义词典中的关系信息提炼向量空间表示的方法，通过鼓励关联词具有相似的向量表示，并且不考虑输入向量是如何构造的。在一系列标准的词汇语义评价任务的基础上，我们从多种词汇向量模型入手，得到了实质性的改进。我们的细化方法在将语义词汇整合到词向量训练算法中方面优于先前的技术。

<h3>1 引言</h3>

数据驱动的词向量学习是自然语言处理中的一项重要技术。这些词向量可以反过来用于识别语义相关的词对(Turney, 2006;Agirre et al.， 2009)或作为下游文本处理应用的特征(Turian et al.， 2010;郭等，2014)。人们使用多种方法来构建词汇的向量空间嵌入，特别是使用同现统计量的低秩近似(Deerwester et al.， 1990)和使用单词序列的神经网络模型的内部表示(Collobert和Weston, 2008)。

由于向量作为词的语义表征在句子中的价值，提高向量质量的研究越来越多。语义词典提供了关于单词语义的类型级信息，通常通过识别同义词、上位关系、上下义和意译关系来提供，这应该是提高词汇质量的宝贵资源仅在未标记语料库上训练的词向量。这类资源的例子包括WordNet (Miller, 1995)、FrameNet (Baker等人，1998)和释义数据库(Ganitkevitch等人，2013)。

最近的工作表明，通过改变神经语言模型中的词向量训练算法的目标(Yu和Dredze, 2014;Xu et al.， 2014;Bian et al.， 2014;Fried and Duh, 2014)或通过谱词向量模型中共现矩阵的关系专一性增宽来整合语义知识(Yih et al.， 2012;Chang et al.， 2013)，可以提高词向量的质量。然而，这些方法仅限于构造向量的特定方法。

本文的贡献是基于图的学习技术，利用词汇关系资源获得更高质量的语义向量，我们称之为改进。与之前的工作相比，改进是作为后处理步骤使用的，通过在由词典派生的关系信息构建的图上运行信念传播来更新单词向量(2)。这允许对使用任何向量训练模型获得的预先训练的单词向量使用改进。直观上，我们的方法鼓励新向量(i)类似于相关单词类型的向量，(ii)类似于它们的纯分布表示。该方法的改进速度快，对于10万字、向量长度300的图只需要5秒左右，且其运行时间独立于原始的词向量训练模型。

![1631581022(1)](\PaperImges\9-13Retrofitting\1631581022(1).jpg)

<center>图1:单词图，相关单词之间的边缘显示了观察到的(灰色)和推断出的(白色)单词向量表示。</center>

实验表明，我们的方法在使用不同种类的语义词典的不同的最先进的词向量模型中工作得很好，并在各种基准上给出了实质性的改进，同时击败了在向量训练中合并语义信息的当前最先进的方法，并微不足道地扩展到多种语言。我们表明，在不同词向量长度的评价基准上，改进提供了一致的性能改进，并显示了改进对词向量质量的影响的定性可视化。改装工具可在: [](https://github.com/mfaruqui/retrofitting)

<h3>2 基于语义词典的改进</h3>

设V = {w1，…， wn}是一个词汇表，即单词类型的集合，是V中对单词之间的语义关系进行编码的本体。我们将其表示为一个无向图(V, E)，每个单词类型都有一个顶点和表示感兴趣的语义关系的边(wi, wj) E V V。这些关系在不同的语义词汇中有所不同，稍后将进行描述(4)。

矩阵Q将是每个wi V的向量表示Q i rd的集合，使用标准的数据驱动技术学习，其中d是单词向量的长度。我们的目标是学习矩阵Q = (q1，…(如qn)，使得这两列(在距离度量下)都接近于Q中的对应列，也接近于Q中的相邻顶点。图1显示了具有这种边连接的小字图;白节点用待改造的Q向量标记(对应VΩ);阴影节点用qˆ中观测到的相应向量进行标记。这个图可以解释为一个马尔可夫随机场(Kindermann and Snell，1980)。

一对向量之间的距离被定义为欧氏距离。因为我们想要推断出的词向量接近于观测值q i和它的邻居qj, j，使(i, j) E，目标被最小化：

![1631582097(1)](PaperImges\9-13Retrofitting\1631582097(1).jpg)

其中α和β值控制关联的相对强度(详见§6.1)。

在这种情况下，我们首先训练独立于语义词典中的信息的词向量，然后对其进行重构。Ψ在Q中是凸的，它的解可以通过求解一个线性方程组得到。为此，我们使用了一种高效的迭代更新方法(Bengio et al.， 2006;Subramanya et al.， 2010;Das and Petrov, 2011;Das and Smith, 2011)。Q中的向量被初始化为等于Q中的向量。我们取Ψ对一个qi向量的一阶导数，并将其等于零，得到以下在线更新：

![1631582173(1)](PaperImges\9-13Retrofitting\1631582173(1).jpg)

在实践中，运行该程序10次迭代收敛到相邻顶点的欧氏距离变化小于10 2。上述的改造方法是模块化的;它可以应用于从任何模型获得的词向量表示，因为Eq. 1中的更新与原始向量训练模型目标无关。

<h4>学习中的语义词汇</h4>

我们提出的方法让人想起最近利用词汇资源改进词向量的工作(Yu and Dredze, 2014;Bian et al.， 2014;Xu et al.， 2014)，它通过先验(或正则化器)改变原始向量训练模型的学习目标，鼓励语义相关的向量(in)紧密相连，但我们的技术被应用于学习的第二阶段。我们在这里描述前面的方法，因为它将作为一个基线。语义词汇在这里扮演着先验Q的角色，我们将其定义如下:

![1631582313(1)](PaperImges\9-13Retrofitting\1631582313(1).jpg)

在这里，γ是一个超参数，它控制先验的强度。就像在改造目标中一样，单词向量参数的先验迫使词典中连接的单词有相似的向量表示，如Ψ(Q) (Q的作用由经验分布的交叉熵来扮演)。

这种先验可以通过最大后验(MAP)估计在学习过程中被纳入。由于不存在估计的闭解，我们考虑两个迭代过程。首先，我们使用对数似然(由现有向量学习模型给出)和对数先验(由Eq. 2)对Q的梯度和进行学习。由于计算Eq. 2的梯度在词汇量为n的情况下具有线性运行时间，所以我们在训练期间对每k个单词使用延迟更新(Carpenter, 2008)。我们称之为MAP的惰性方法。第二种方法是对对数似然进行随机梯度上升，每k个单词之后对Eq. 1进行更新。我们称之为周期法。我们稍后将这些方法与改造方法进行实验比较(6.2)。

<h3>3 词向量表示</h3>

现在，我们将描述各种公开可用的预先训练过的英语单词向量，并在其上测试改造模型的适用性。选择这些向量是为了在大量和少量未标记文本以及训练词向量的神经和光谱方法之间实现平衡混合。

<h4>Glove向量</h4>

单词表示的全局向量(Pennington et al.， 2014)是在从语料库中聚集的全局词-词共现统计数据上训练的，结果表示显示了单词向量空间有趣的线性子结构。这些向量是根据维基百科和英语Gigaword中的60亿个单词训练的，长度为300。

![1631582510(1)](PaperImges\9-13Retrofitting\1631582510(1).jpg)

<center>表1：从不同的词汇表得到的图形的近似大小。</center>

<h4>Skip-Gram向量</h4>

word2vec工具(Mikolov et al.， 2013a)快速且目前被广泛使用。在该模型中，每个单词的Huffman代码被用作具有连续投影层的对数线性分类器的输入，并对给定上下文窗口中的单词进行预测。可用向量在谷歌新闻数据集的1000亿个单词上训练，长度为300。

<h4>Global Context向量</h4>

这些向量是使用包含局部和全局(文档级)上下文特征的递归神经网络学习的(Huang et al.， 2012)。这些向量是根据英语维基百科的前10亿个单词训练的，长度为50。

<h4>Multilingual向量</h4>

Faruqui和Dyer(2014)首先对不同语言的文本进行SVD，然后对平行语料库中对齐的单词的向量对应用典型相关分析(canonical correlation analysis, CCA)来学习向量。使用WMT-2011英语、法语、德语和西班牙语新闻语料库对单语向量进行训练。我们用英语单词矢量投影在普通的英语德语空间里。单语英语WMT语料库有3.6亿词，训练向量长度为512。

<h3>4 语义词典</h3>

我们使用三种不同的语义词汇来评估它们在改进词向量方面的效用。我们包括手动和自动创建的词汇表。表1显示了从这些词汇表获得的图的大小。

<h4>PPDB</h4>

WordNet (Miller, 1995)是一个大型的人工构建的英语词汇语义库。它将英语单词分组为称为synsets的同义词集，提供简短的通用定义，并记录synsets之间的各种语义关系。这个数据库的结构是一个图，特别适合我们的任务，因为它显式地将概念与语义对齐的关系(如上义词和下义词)联系起来。例如，“dog”是“canine”的同义词，“puppy”的上义，“animal”的下义。我们使用WordNet进行了两个不同的实验:(1)只将单词与同义词连接，(2)将单词与同义词、上词和下词连接。我们将这两个图分别称为WNsyn和WNall。在这两种设置中，所有αi都被设为1，βij为(i)级1。

<h4>FrameNet</h4>

rameNet (Baker et al.， 1998;Fillmore et al.， 2003)是一个丰富的语言资源，包含了英语词汇和谓词论证语义的信息。框架可以由多种不同的词类型在表面上实现，这就意味着引起相同框架的词类型应该是语义相关的。例如，在一个比例中，位置的变化与推动、提高和生长(在许多其他方面)有关。在我们使用frameet时，两个与任何帧组合在一起的单词在e中被赋予了一条边。我们将这个图称为FN。所有αi均设为1，βij为(i)级1。

<h3>5 评价基准</h3>

我们在任务中评估单词向量表示的质量，测试它们在语义和句法方面的捕获情况，以及外部情感分析任务。

<h4>词相似度</h4>

我们根据各种不同的基准来评估我们的词表示，这些基准已被广泛用于衡量词的相似性。第一个是WS-353数据集(Finkelstein et al.， 2001)，其中包含353对由人类分配的相似度评分的英语单词。第二个基准是RG-65 (Rubenstein和Goodenough, 1965)数据集，它包含65对名词。由于常用的词相似度数据集包含少量的词对，我们也使用MEN数据集(Bruni et al.， 2012)，该数据集从一个大型网络语料库中至少出现700次的词中取样3000个词对。我们计算构成测试项目的两个词的向量之间的余弦相似度，并报告由我们的模型生成的排名与人类排名之间的Spearman排名相关系数(Myers和Well, 1995)。

<h4>句法关系</h4>

Mikolov等人(2013b)提出了一个由类似词对组成的句法关系数据集。它包含遵循共同语法关系的单词关系的对元组。例如，给定walking和walked，这两个词是同一个动词的不同屈折变化形式。有9种不同的关系，总的来说有10675对语法词元组。任务是找到一个词d，它最适合以下关系:a是b, c是d，给定a, b，和c。我们使用向量偏移方法(Mikolov et al.， 2013a;Levy and Goldberg, 2014)，计算q = qa qb +qc，从q中返回与q余弦相似度最高的向量。

<h4>同义词选择</h4>

托福考试的同义词选择任务是从四个候选词中选择语义上最接近目标的词(Landauer and Dumais, 1997)。数据集包含80个这样的问题。例如rug {sofa, ottoman, carpet，门厅}，carpet是最接近目标的同义词。

<h4>语义分析</h4>

Socher等人(2013)创建了一个树库，其中包含从电影评论节选中选取的短语和句子，用精细的情感标签标注的句子。粗粒度的正类和负类树库被分成训练、开发和测试数据集，分别包含6,920、872和1,821个句子。我们根据给定句子的词向量的平均值训练一个' 2正则logistic回归分类器，以预测句子层次上的粗粒度情感标签，并报告分类器的测试集准确性。

<h3>6 实验</h3>

我们首先展示了测试改进方法(6.1)的改进的实验，然后比较了在MAP学习中使用词汇(6.2)和其他公布的方法(6.3)。然后我们测试改进的泛化对其他语言的效果如何(6.4)。

<h4> 6.1 改进</h4>

我们使用Eq. 1来使用从语义词汇(§4)衍生的图来改进词向量(§3)。

<h4>结果</h4>

表2显示了使用不同语义词汇表(行)的不同任务(列)的绝对性能变化。所有的词典都在单词相似度任务(前三列)上提供了很高的改进。在托福考试中，我们观察到，除了框架网以外，所有词汇的准确性都有了很大的提高，提高了10个绝对点数。帧网的性能较弱，在某些情况下导致性能更差(例如，手套和SG向量)。对于外部情感分析任务，我们观察到使用所有词汇的改进，Multi向量在基线上的准确率增加了1.4%(绝对)。这一增长在统计上是显著的(p &lt;0.01, McNemar检验法)。

我们观察到手套和SG向量的改进，手套和SG向量在除SYN-REL以外的所有任务上都在数十亿令牌上训练。对于较强的基线(Glove和Multi)，我们观察到的改善比较低的基线分数(SG和GC)要小。我们认为，框架网的表现不如其他词汇，因为它的框架是基于非常抽象的概念;通常意义看似遥远的词(例如，推动和增长)也能唤起同样的框架。有趣的是，我们几乎从来没有改进过SYN-REL任务，特别是在更高的基线上，这可以归因于这样一个事实，即SYN-REL任务本质上是一个语法任务，在改进过程中，我们在向量中加入了额外的语义信息。综上所述，我们发现PPDB在不同向量类型上的最大聚合次数改进效果最好，紧随其后的是WNall，而改进则在任务和向量之间获得了收益。一个整体词典，其图是WNall和PPDB词典的并集，平均性能略低于PPDB;为了简洁起见，我们在这里省略这些结果。

<h4>6.2 语义词库在学习过程中</h4>

为了在训练过程中整合词汇信息，并比较其与改进的性能，我们训练了对数双线性(LBL)向量(Mnih和Teh, 2012)。这些向量经过训练，以优化语言模型的对数似然性，该模型预测给定上下文(h)中的单词集的单词标记w s向量，也表示为向量

![1631606820(1)](PaperImges\9-13Retrofitting\1631606820(1).jpg)

我们利用2中描述的懒惰和周期性技术，结合Eq. 2中定义的先验，优化上述可能性。由于计算整个词汇的分割函数代价昂贵，我们使用AdaGrad (Duchi et al.， 2010)使用噪声对比估计(NCE)来估计模型的参数(Mnih和Teh, 2012)，学习率为0.05。

![1631606863](PaperImges\9-13Retrofitting\1631606863.jpg)

表2:改装后的绝对性能变化。在不同的任务中，斯皮尔曼的相关性(左3栏)和准确性(右3栏)。分数越高越好。粗体表示向量类型的最大改进。

![1631606906(1)](PaperImges\9-13Retrofitting\1631606906(1).jpg)

表3:在训练LBL向量时，加入PPDB信息的绝对性能变化。在不同的任务中，斯皮尔曼的相关性(左3栏)和准确性(右3栏)。加粗表示进步最大。

我们在包含3.6亿词的WMT-2011新闻语料库上训练长度为100的向量，并使用PPDB作为语义词典，因为PPDB在改进实验中表现良好(6.1)。对于惰性方法，我们每k = 100,000 words7对先验进行更新，并测试不同的先验强度γ{1,0.1, 0.01}值。对于周期方法，我们使用Eq. 1每k{25, 50, 100}百万单词更新单词向量。

<h4>结果</h4>

见表3。对于惰性，γ = 0.01效果最好，但大多数情况下该方法对γ s值不敏感。对于周期性的(总体上比惰性的改进更大)，k = 50M的性能最好，尽管k的所有其他值也优于基线。改进可以应用于任何单词向量，不管它们是如何训练的，它是有竞争力的，有时甚至更好

![1631606975(1)](PaperImges\9-13Retrofitting\1631606975(1).jpg)

*译文：*表4:针对Yu和Dredze (2014)， Xu et al.(2014)对语义丰富的改进进行比较。Spearman相关性(左3列)和准确性(右3列)的差异

<h4>6.3 和之前工作的比较</h4>

之前的两个模型(Yu and Dredze, 2014;Xu et al.， 2014)的研究表明，使用word2vec工具获得的词向量的质量可以通过词汇的语义知识得到提高。这两种模型在训练过程中都将单词间的约束作为训练目标的正则化术语，其方法只能用于提高word2vec工具生成的SG和CBOW向量的质量。我们比较了我们的向量和这些向量的质量。

<h4>Yu and Dredze</h4>

