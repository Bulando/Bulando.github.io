<h2>LSTMEmbed:Learning Word and Sense Representations from a Large Semantically Annotated Corpus with Long Short-Term Memories论文翻译</h2>

<h2>LSTMEmbed:长短期记忆网络从一个大的语义标记语料中学习词语和意思的表征</h2>


<h3>摘要</h3>

词汇嵌入是目前大多数自然语言处理任务中词汇事实上的标准表征，但近年来人们的注意力转向了向量表征，该表征捕获了词汇的不同含义，即意思。在本文中，我们探讨了双向LSTM模型从语义标注语料库中学习词义表示的能力。我们展示了使用一个意识到词序的体系结构(如LSTM)，使我们能够创建更好的表示。我们在评估语义表示的各种标准基准上评估我们提出的模型，在SemEval2014单词到语义的相似性任务上达到了最先进的性能。我们在http://lcl.uniroma1上发布代码和生成的单词和语义嵌入。它/ LSTMEmbed。

<h3>1 引言</h3>

出于交流效率的考虑，自然语言本质上是模棱两可的(Piantadosi et al.， 2012)。对我们人类来说，歧义不是问题，因为我们用共同的知识来填补空白，相互理解。因此，一个适合理解自然语言和与人类并肩工作的计算模型应该能够在一定程度上处理歧义(Navigli, 2018)。创建此类计算机系统的一个必要步骤是构建单词及其含义的正式表示，要么以大型知识库(如语义网络)的形式，要么以几何空间中的向量的形式(Navigli和Martelli, 2019)。

